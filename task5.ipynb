{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def prepare(dataset):\n",
    "    # 源数据\n",
    "    data = dataset.copy()\n",
    "    # 标记是否为满减\n",
    "    data['is_manjian'] = data['Discount_rate'].map(lambda x: 1 if ':' in str(x) else 0)\n",
    "    #计算折扣率\n",
    "    data['discount_rate'] = data['Discount_rate'].map(lambda x: float(x)\n",
    "    if ':' not in str(x)\n",
    "    else\n",
    "    (float(str(x).split(':')[0]) - float(str(x).split(':')[1])) / float(str(x).split(':')[0]))\n",
    "    # 计算满减的最低消费\n",
    "    data['min_cost_of_manjian'] = data['Discount_rate'].map(\n",
    "        lambda x: -1 if ':' not in str(x) else int(str(x).split(':')[0]))\n",
    "    # 距离处理，空距离填充为-1\n",
    "    data['Distance'].fillna(-1, inplace=True)\n",
    "    data['null_distance'] = data['Distance'].map(lambda x: 1 if x == -1 else 0)\n",
    "    # 时间处理\n",
    "    data['date_received'] = pd.to_datetime(data['Date_received'], format='%Y%m%d')\n",
    "    #对训练集特殊处理\n",
    "    #将训练集中的每一个 column 转换成列表\n",
    "    if 'Date' in data.columns.tolist():\n",
    "        data['date'] = pd.to_datetime(data['Date'], format='%Y%m%d')\n",
    "    # 返回\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_label(dataset):\n",
    "    # 源数据\n",
    "    data = dataset.copy()\n",
    "    # 打标:领券后 15 天内消费为 1,否则为 0\n",
    "    data['label'] = list(map(lambda x, y: 1 if (x - y).total_seconds() / (60 * 60 * 24)\n",
    "                                               <= 15 else 0, data['date'], data['date_received']))\n",
    "    # 返回\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_feature(label_field):\n",
    "    # 源数据\n",
    "    data = label_field.copy()\n",
    "    # 将 Coupon_id 列中 float 类型的元素转换为 int 类型\n",
    "    data['Coupon_id'] = data['Coupon_id'].map(int)\n",
    "    # 将 Date_received 列中 float 类型的元素转换为 int 类型\n",
    "    data['Date_received'] = data['Date_received'].map(int)\n",
    "    data['cnt'] = 1  # 方便特征提取\n",
    "    # 返回的特征数据集\n",
    "    feature = data.copy()\n",
    "    ######################1、用户领券数#################\n",
    "    keys = ['User_id']  # 主键为用户\n",
    "    prefixs = 'simple_' + '_'.join(keys) + '_'\n",
    "    pivot = pd.pivot_table(data, index=keys, values='cnt', aggfunc=len)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'cnt': prefixs +\n",
    "                                                       'receive_cnt'}).reset_index()\n",
    "    # 将 id 列与特征列左连\n",
    "    feature = pd.merge(feature, pivot, on=keys, how='left')\n",
    "    ######################2、用户领取特定优惠券数####################\n",
    "    keys = ['User_id', 'Coupon_id']  # 主键\n",
    "    prefixs = 'simple_' + '_'.join(keys) + '_'\n",
    "    pivot = pd.pivot_table(data, index=keys, values='cnt', aggfunc=len)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'cnt': prefixs +\n",
    "                                                       'receive_cnt'}).reset_index()\n",
    "    feature = pd.merge(feature, pivot, on=keys, how='left')\n",
    "    ######################3、用户当天领券数######################\n",
    "    keys = ['User_id', 'Date_received']  # 主键\n",
    "    prefixs = 'simple_' + '_'.join(keys) + '_'\n",
    "    pivot = pd.pivot_table(data, index=keys, values='cnt', aggfunc=len)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'cnt': prefixs +\n",
    "                                                       'receive_cnt'}).reset_index()\n",
    "    feature = pd.merge(feature, pivot, on=keys, how='left')\n",
    "    ######################4、用户当天领取特定优惠券数######################\n",
    "    keys = ['User_id', 'Coupon_id', 'Date_received']  # 主键\n",
    "    prefixs = 'simple_' + '_'.join(keys) + '_'\n",
    "    pivot = pd.pivot_table(data, index=keys, values='cnt', aggfunc=len)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'cnt': prefixs +\n",
    "                                                       'receive_cnt'}).reset_index()\n",
    "    feature = pd.merge(feature, pivot, on=keys, how='left')\n",
    "    ####################5、用户是否在同一天重复领取了特定优惠券####################\n",
    "    keys = ['User_id', 'Coupon_id', 'Date_received']  # 主键\n",
    "    prefixs = 'simple_' + '_'.join(keys) + '_'\n",
    "    pivot = pd.pivot_table(data, index=keys, values='cnt', aggfunc=lambda x: 1 if len(x) >\n",
    "                                                                                  1 else 0)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'cnt': prefixs +\n",
    "                                                       'repeat_receive'}).reset_index()\n",
    "    feature = pd.merge(feature, pivot, on=keys, how='left')\n",
    "    # 删除辅助提特征的'cnt'\n",
    "    feature.drop(['cnt'], axis=1, inplace=True)\n",
    "    # 返回\n",
    "    return feature"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def get_shiyanwu_feature(label_field):\n",
    "    # 源数据\n",
    "    data = label_field.copy()\n",
    "    data['Coupon_id'] = data['Coupon_id'].map(int)\n",
    "    data['Date_received'] = data['Date_received'].map(int)\n",
    "    data['cnt'] = 1  # 方便特征提取\n",
    "    # 主键\n",
    "    keys = ['User_id']\n",
    "    # 特征名前缀,由 history_field 和主键组成\n",
    "    prefixs = 'history_field_' + '_'.join(keys) + '_'\n",
    "    # 返回的特征数据集\n",
    "    u_feat = label_field[keys].drop_duplicates(keep='first')\n",
    "    ######################1、用户领券数######################\n",
    "    pivot = pd.pivot_table(data, index=keys, values='cnt', aggfunc=len)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'cnt': prefixs +\n",
    "                                                       'receive_cnt'}).reset_index()\n",
    "    u_feat = pd.merge(u_feat, pivot, on=keys, how='left')\n",
    "    u_feat.fillna(0, downcast='infer', inplace=True)\n",
    "\n",
    "    ######################2、在多少不同商家领取优惠券######################\n",
    "    pivot = pd.pivot_table(data, index=keys, values='Merchant_id', aggfunc=lambda x:\n",
    "    len(str(x)))\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Merchant_id': prefixs +\n",
    "                                                               'receive_differ_Merchant_cnt'}).reset_index()\n",
    "    u_feat = pd.merge(u_feat, pivot, on=keys, how='left')\n",
    "    u_feat.fillna(0, downcast='infer', inplace=True)\n",
    "\n",
    "    ######################3、领券并消费数######################\n",
    "    pivot = pd.pivot_table(data[data['Date'].map(lambda x: str(x) != 'nan')],\n",
    "                           index=keys, values='cnt', aggfunc=len)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'cnt': prefixs +\n",
    "                                                       'receive_and_consume_cnt'}).reset_index()\n",
    "    u_feat = pd.merge(u_feat, pivot, on=keys, how='left')\n",
    "    u_feat.fillna(0, downcast='infer', inplace=True)\n",
    "\n",
    "    ######################4、领券未消费数######################\n",
    "    pivot = pd.pivot_table(data[data['Date'].map(lambda x: str(x) == 'nan')],\n",
    "                           index=keys, values='cnt', aggfunc=len)\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'cnt': prefixs +\n",
    "                                                       'receive_not_consume_cnt'}).reset_index()\n",
    "    u_feat = pd.merge(u_feat, pivot, on=keys, how='left')\n",
    "    u_feat.fillna(0, downcast='infer', inplace=True)\n",
    "\n",
    "    ######################5、核销率######################\n",
    "    u_feat[prefixs + 'receive_and rate'] = list(map(lambda x, y: x / y if y != 0 else 0,\n",
    "                                                    u_feat[prefixs + 'receive_and_consume_cnt'],\n",
    "                                                    u_feat[prefixs + 'receive_cnt']))\n",
    "\n",
    "    ######################6、领取并消费优惠券的平均折扣率######################\n",
    "    pivot = pd.pivot_table(data[data['Date'].map(lambda x: str(x) == 'nan')],\n",
    "                           index=keys, values='cnt', aggfunc=\"mean\")\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'discount_rate': prefixs +\n",
    "                                                                 'receive_and_consume_mean_discount_rate'}).reset_index()\n",
    "    u_feat = pd.merge(u_feat, pivot, on=keys, how='left')\n",
    "    u_feat.fillna(0, downcast='infer', inplace=True)\n",
    "\n",
    "    ######################7、领取并消费优惠券的平均距离######################\n",
    "    data_half = data[data['Distance'].map(lambda x: int(x) != -1)]\n",
    "    data_ = data_half[data_half['Date'].map(lambda x: str(x) != 'nan')]\n",
    "    pivot = pd.pivot_table(data_, index=keys, values='Distance', aggfunc=\"mean\")\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Distance': prefixs +\n",
    "                                                            'receive_and_consume_mean_distance'}).reset_index()\n",
    "    u_feat = pd.merge(u_feat, pivot, on=keys, how='left')\n",
    "    u_feat.fillna(0, downcast='infer', inplace=True)\n",
    "    ######################8、在多少不同商家领取并消费优惠券######################\n",
    "    pivot = pd.pivot_table(data[data['Date'].map(lambda x: str(x) == 'nan')],\n",
    "                           index=keys, values='Merchant_id', aggfunc=lambda x: len(str(x)))\n",
    "    pivot = pd.DataFrame(pivot).rename(columns={'Merchant_id': prefixs +\n",
    "                                                               'receive_and_consume_differ_Merchant_cnt'}).reset_index()\n",
    "    u_feat = pd.merge(u_feat, pivot, on=keys, how='left')\n",
    "    u_feat.fillna(0, downcast='infer', inplace=True)\n",
    "\n",
    "    ######################9、在多少不同商家领取并消费优惠券######################\n",
    "    u_feat[prefixs + 'receive_differ_Merchant_consume_rate'] = list(map(lambda x, y: x / y\n",
    "    if y != 0 else 0, u_feat[prefixs +\n",
    "                             'receive_and_consume_differ_Merchant_cnt'], u_feat[\n",
    "                                                                            prefixs + 'receive_differ_Merchant_cnt']))\n",
    "    #添加特征\n",
    "    history_feat = label_field.copy()\n",
    "    #添加用户特征\n",
    "    history_feat = pd.merge(history_feat, u_feat, on=['User_id'], how='left')\n",
    "    #返回\n",
    "    return history_feat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def get_week_feature(label_field):\n",
    "    # 源数据\n",
    "    data = label_field.copy()\n",
    "    data['Coupon_id'] = data['Coupon_id'].map(int)\n",
    "    data['Date_received'] = data['Date_received'].map(int)\n",
    "    # 返回的处理好的特征数据集\n",
    "    feature = data.copy()\n",
    "    ######################1、星期几######################\n",
    "    feature['week'] = feature['date_received'].map(lambda x: x.weekday())\n",
    "    ######################2、判断领券日是否为休息日######################\n",
    "    feature['is_weekend'] = feature['week'].map(lambda x: 1 if x == 5 or x == 6 else 0)\n",
    "    ######################3、one-hot 离散星期几，前缀使用 week_######################\n",
    "    feature = pd.concat([feature, pd.get_dummies(feature['week'], prefix='week')],\n",
    "                        axis=1)\n",
    "    feature.index = range(len(feature))  # 重置 index\n",
    "    # 返回\n",
    "    return feature\n",
    "\n",
    "\n",
    "def get_dataset(history_field, middle_field, label_field):\n",
    "    # 特征工程\n",
    "    week_feat = get_week_feature(label_field)  # 日期特征\n",
    "    simple_feat = get_feature(label_field)  # 示例简单特征\n",
    "    history_feat = get_shiyanwu_feature(label_field)  #实验五需要的特征\n",
    "    # 构造数据集'''\n",
    "    share_characters = list(\n",
    "        set(simple_feat.columns.tolist()) & set(week_feat.columns.tolist()) &\n",
    "        set(history_feat.columns.tolist()) & set(label_field.columns.tolist()))\n",
    "    label_field.index = range(len(label_field))\n",
    "    dataset = pd.concat([label_field, simple_feat.drop(share_characters, axis=1)],\n",
    "                        axis=1)\n",
    "    dataset = pd.concat([dataset, history_feat.drop(share_characters, axis=1)], axis=1)\n",
    "    dataset = pd.concat([dataset, week_feat.drop(share_characters, axis=1)], axis=1)\n",
    "    # 删除无用属性并将 label 置于最后一列\n",
    "    if 'Date' in dataset.columns.tolist():  # 表示训练集和验证集\n",
    "        dataset.drop(['Merchant_id', 'Discount_rate', 'Date', 'date_received', 'date'],\n",
    "                     axis=1, inplace=True)\n",
    "        label = dataset['label'].tolist()\n",
    "        dataset.drop(['label'], axis=1, inplace=True)\n",
    "        dataset['label'] = label\n",
    "    else:\n",
    "        dataset.drop(['Merchant_id', 'Discount_rate', 'date_received'], axis=1,\n",
    "                     inplace=True)\n",
    "    # 修正数据类型\n",
    "    dataset = dataset.dropna()\n",
    "    dataset = dataset.dropna(how='any', subset=['User_id'], inplace=False)\n",
    "    dataset['User_id'] = dataset['User_id'].map(int)\n",
    "    dataset['Coupon_id'] = dataset['Coupon_id'].map(int)\n",
    "    dataset['Date_received'] = dataset['Date_received'].map(int)\n",
    "    dataset['Distance'] = dataset['Distance'].map(int)\n",
    "    if 'label' in dataset.columns.tolist():\n",
    "        dataset['label'] = dataset['label'].map(int)\n",
    "    # 去重\n",
    "    dataset.drop_duplicates(keep='first', inplace=True)\n",
    "    dataset.index = range(len(dataset))\n",
    "    # 返回\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def model_xgb(train, test):\n",
    "    # xgb 参数\n",
    "    params = {'booster': 'gbtree',\n",
    "              'objective': 'binary:logistic',\n",
    "              'eval_metric': 'auc',\n",
    "              'silent': 1,\n",
    "              'eta': 0.01,\n",
    "              'max_depth': 5,\n",
    "              'min_child_weight': 3,\n",
    "              'gamma': 0.4,\n",
    "              'lambda': 1,\n",
    "              'colsample_bylevel': 0.8,\n",
    "              'colsample_bytree': 0.7,\n",
    "              'subsample': 0.9,\n",
    "              'scale_pos_weight': 1}\n",
    "    # 数据集\n",
    "    dtrain = xgb.DMatrix(train.drop(['User_id', 'Coupon_id', 'Date_received', 'label'],\n",
    "                                    axis=1), label=train['label'])\n",
    "    dtest = xgb.DMatrix(test.drop(['User_id', 'Coupon_id', 'Date_received'], axis=1))\n",
    "    # 训练\n",
    "    watchlist = [(dtrain, 'train')]\n",
    "    model = xgb.train(params, dtrain, num_boost_round=10, evals=watchlist)\n",
    "    # 预测\n",
    "    predict = model.predict(dtest)\n",
    "    # 处理结果\n",
    "    predict = pd.DataFrame(predict, columns=['prob'])\n",
    "    result = pd.concat([test[['User_id', 'Coupon_id', 'Date_received']], predict],\n",
    "                       axis=1)\n",
    "    # 特征重要性\n",
    "    feat_importance = pd.DataFrame(columns=['feature_name', 'importance'])\n",
    "    feat_importance['feature_name'] = model.get_score().keys()\n",
    "    feat_importance['importance'] = model.get_score().values()\n",
    "    feat_importance.sort_values(['importance'], ascending=False, inplace=True)\n",
    "    # 返回\n",
    "    return result, feat_importance\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "构造训练集\n",
      "构造验证集\n",
      "构造测试集\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Date'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32mE:\\code\\pycharm\\learn\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3651\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3652\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3653\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mE:\\code\\pycharm\\learn\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mE:\\code\\pycharm\\learn\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'Date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[34], line 36\u001B[0m\n\u001B[0;32m     34\u001B[0m validate \u001B[38;5;241m=\u001B[39m get_dataset(validate_history_field, validate_middle_field, validate_label_field)\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m构造测试集\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 36\u001B[0m test \u001B[38;5;241m=\u001B[39m \u001B[43mget_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_history_field\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_middle_field\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_label_field\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m# 线上训练\u001B[39;00m\n\u001B[0;32m     38\u001B[0m big_train \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([train, validate], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "Cell \u001B[1;32mIn[32], line 24\u001B[0m, in \u001B[0;36mget_dataset\u001B[1;34m(history_field, middle_field, label_field)\u001B[0m\n\u001B[0;32m     22\u001B[0m week_feat \u001B[38;5;241m=\u001B[39m get_week_feature(label_field)  \u001B[38;5;66;03m# 日期特征\u001B[39;00m\n\u001B[0;32m     23\u001B[0m simple_feat \u001B[38;5;241m=\u001B[39m get_feature(label_field)  \u001B[38;5;66;03m# 示例简单特征\u001B[39;00m\n\u001B[1;32m---> 24\u001B[0m history_feat \u001B[38;5;241m=\u001B[39m \u001B[43mget_shiyanwu_feature\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabel_field\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m#实验五需要的特征\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m# 构造数据集'''\u001B[39;00m\n\u001B[0;32m     26\u001B[0m share_characters \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;28mset\u001B[39m(simple_feat\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mtolist()) \u001B[38;5;241m&\u001B[39m \u001B[38;5;28mset\u001B[39m(week_feat\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mtolist()) \u001B[38;5;241m&\u001B[39m\n\u001B[0;32m     28\u001B[0m     \u001B[38;5;28mset\u001B[39m(history_feat\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mtolist()) \u001B[38;5;241m&\u001B[39m \u001B[38;5;28mset\u001B[39m(label_field\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mtolist()))\n",
      "Cell \u001B[1;32mIn[28], line 29\u001B[0m, in \u001B[0;36mget_shiyanwu_feature\u001B[1;34m(label_field)\u001B[0m\n\u001B[0;32m     26\u001B[0m u_feat\u001B[38;5;241m.\u001B[39mfillna(\u001B[38;5;241m0\u001B[39m, downcast\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minfer\u001B[39m\u001B[38;5;124m'\u001B[39m, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m######################3、领券并消费数######################\u001B[39;00m\n\u001B[1;32m---> 29\u001B[0m pivot \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mpivot_table(data[\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mDate\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mmap(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;28mstr\u001B[39m(x) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnan\u001B[39m\u001B[38;5;124m'\u001B[39m)],\n\u001B[0;32m     30\u001B[0m                        index\u001B[38;5;241m=\u001B[39mkeys, values\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcnt\u001B[39m\u001B[38;5;124m'\u001B[39m, aggfunc\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m)\n\u001B[0;32m     31\u001B[0m pivot \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(pivot)\u001B[38;5;241m.\u001B[39mrename(columns\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcnt\u001B[39m\u001B[38;5;124m'\u001B[39m: prefixs \u001B[38;5;241m+\u001B[39m\n\u001B[0;32m     32\u001B[0m                                                    \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreceive_and_consume_cnt\u001B[39m\u001B[38;5;124m'\u001B[39m})\u001B[38;5;241m.\u001B[39mreset_index()\n\u001B[0;32m     33\u001B[0m u_feat \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mmerge(u_feat, pivot, on\u001B[38;5;241m=\u001B[39mkeys, how\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mE:\\code\\pycharm\\learn\\venv\\lib\\site-packages\\pandas\\core\\frame.py:3760\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3758\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3759\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3760\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3761\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3762\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32mE:\\code\\pycharm\\learn\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3652\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3653\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3654\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3655\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3656\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3657\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3658\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3659\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'Date'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # 源数据\n",
    "    off_train = pd.read_csv('ccf_offline_stage1_train.csv')\n",
    "    off_test = pd.read_csv('ccf_offline_stage1_test_revised.csv')\n",
    "    # 预处理\n",
    "    off_train = prepare(off_train)\n",
    "    off_test = prepare(off_test)\n",
    "    # 打标\n",
    "    off_train = get_label(off_train)\n",
    "    # 划分区间\n",
    "    # 训练集历史区间、中间区间、标签区间\n",
    "    train_history_field = off_train[\n",
    "        off_train['date_received'].isin(pd.date_range('2016/3/2', periods=60))]\n",
    "    train_middle_field = off_train[off_train['date'].isin(pd.date_range('2016/5/1',\n",
    "                                                                        periods=15))]\n",
    "    train_label_field = off_train[\n",
    "        off_train['date_received'].isin(pd.date_range('2016/5/16', periods=31))]\n",
    "    # 验证集历史区间、中间区间、标签区间\n",
    "    validate_history_field = off_train[\n",
    "        off_train['date_received'].isin(pd.date_range('2016/1/16', periods=60))]\n",
    "    validate_middle_field = off_train[\n",
    "        off_train['date'].isin(pd.date_range('2016/3/16', periods=15))]\n",
    "    validate_label_field = off_train[\n",
    "        off_train['date_received'].isin(pd.date_range('2016/3/31', periods=31))]\n",
    "    # 测试集历史区间、中间区间、标签区间\n",
    "    test_history_field = off_train[\n",
    "        off_train['date_received'].isin(pd.date_range('2016/4/17', periods=60))]\n",
    "    test_middle_field = off_train[off_train['date'].isin(pd.date_range('2016/6/16', periods=15))]\n",
    "    test_label_field = off_test.copy()\n",
    "    # 构造训练集、验证集、测试集\n",
    "    print('构造训练集')\n",
    "    train = get_dataset(train_history_field, train_middle_field, train_label_field)\n",
    "    print('构造验证集')\n",
    "    validate = get_dataset(validate_history_field, validate_middle_field, validate_label_field)\n",
    "    print('构造测试集')\n",
    "    test = get_dataset(test_history_field, test_middle_field, test_label_field)\n",
    "    # 线上训练\n",
    "    big_train = pd.concat([train, validate], axis=0)\n",
    "    result, feat_importance = model_xgb(big_train, test)\n",
    "    # 保存\n",
    "    result.to_csv(r'easy.csv', index=False, header=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
